nohup: ignoring input
File /workspaces/storch/data/input.txt already exists.
chars = 
,  , !, $, &, ', ,, -, ., 3, :, ;, ?, A, B, C, D, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z, a, b, c, d, e, f, g, h, i, j, k, l, m, n, o, p, q, r, s, t, u, v, w, x, y, z
vocab_size = 65
"BiGram!" = "BiGram!"
xb:

Not Gloucester's death, nor Hereford's banishment
Not Gaunt's rebukes, nor England's private wrongs,
Nor the prevention of poor Bolingbroke
About his marriage, nor my own disgrace,
Have ever made me sour my patient cheek,
Or bend one wrinkle on my soverei
yb:
Not Gloucester's death, nor Hereford's banishment
Not Gaunt's rebukes, nor England's private wrongs,
Nor the prevention of poor Bolingbroke
About his marriage, nor my own disgrace,
Have ever made me sour my patient cheek,
Or bend one wrinkle on my sovereig
V2
13.443137M parameters
GPTLanguageModel: #282 13443137 (
  token_embedding_table: Embedding(numEmbeddings=65, embeddingDim=384, paddingIdx=None, maxNorm=None, normType=Some(2.0), scaleGradByFreq=false, sparse=false ): #1 <24960> 
  position_embedding_table: Embedding(numEmbeddings=256, embeddingDim=384, paddingIdx=None, maxNorm=None, normType=Some(2.0), scaleGradByFreq=false, sparse=false ): #1 <98304> 
  blocks: Sequential: #276 13294080 (
    0: Block(nEmbed = 384): #46 2215680 (
      sa: MultiHeadAttention(numHeads=6, nEmbed=384, headSize=64, blockSize=256): #38 1032576 (
        hs_0: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_1: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_2: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_3: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_4: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_5: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        heads: ModuleList: #18 442368 (
          0: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          1: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          2: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          3: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          4: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          5: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
        )
        proj: Linear(inFeatures=384, outFeatures=384, bias=true): #2 <147456,384> 
        drop: Dropout(p=0.2, inplace=false): #0 <> 
      )
      ffwd: FeedForward(nEmbed = 384): #4 1181568 (
        net: Sequential: #4 1181568 (
          0: Linear(inFeatures=384, outFeatures=1536, bias=true): #2 <589824,1536> 
          1: ReLU: #0 <> 
          2: Linear(inFeatures=1536, outFeatures=384, bias=true): #2 <589824,384> 
          3: Dropout(p=0.2, inplace=false): #0 <> 
        )
      )
      ln1: TensorModule: #2 <384,384> 
      ln2: TensorModule: #2 <384,384> 
    )
    1: Block(nEmbed = 384): #46 2215680 (
      sa: MultiHeadAttention(numHeads=6, nEmbed=384, headSize=64, blockSize=256): #38 1032576 (
        hs_0: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_1: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_2: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_3: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_4: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_5: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        heads: ModuleList: #18 442368 (
          0: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          1: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          2: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          3: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          4: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          5: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
        )
        proj: Linear(inFeatures=384, outFeatures=384, bias=true): #2 <147456,384> 
        drop: Dropout(p=0.2, inplace=false): #0 <> 
      )
      ffwd: FeedForward(nEmbed = 384): #4 1181568 (
        net: Sequential: #4 1181568 (
          0: Linear(inFeatures=384, outFeatures=1536, bias=true): #2 <589824,1536> 
          1: ReLU: #0 <> 
          2: Linear(inFeatures=1536, outFeatures=384, bias=true): #2 <589824,384> 
          3: Dropout(p=0.2, inplace=false): #0 <> 
        )
      )
      ln1: TensorModule: #2 <384,384> 
      ln2: TensorModule: #2 <384,384> 
    )
    2: Block(nEmbed = 384): #46 2215680 (
      sa: MultiHeadAttention(numHeads=6, nEmbed=384, headSize=64, blockSize=256): #38 1032576 (
        hs_0: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_1: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_2: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_3: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_4: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_5: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        heads: ModuleList: #18 442368 (
          0: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          1: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          2: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          3: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          4: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          5: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
        )
        proj: Linear(inFeatures=384, outFeatures=384, bias=true): #2 <147456,384> 
        drop: Dropout(p=0.2, inplace=false): #0 <> 
      )
      ffwd: FeedForward(nEmbed = 384): #4 1181568 (
        net: Sequential: #4 1181568 (
          0: Linear(inFeatures=384, outFeatures=1536, bias=true): #2 <589824,1536> 
          1: ReLU: #0 <> 
          2: Linear(inFeatures=1536, outFeatures=384, bias=true): #2 <589824,384> 
          3: Dropout(p=0.2, inplace=false): #0 <> 
        )
      )
      ln1: TensorModule: #2 <384,384> 
      ln2: TensorModule: #2 <384,384> 
    )
    3: Block(nEmbed = 384): #46 2215680 (
      sa: MultiHeadAttention(numHeads=6, nEmbed=384, headSize=64, blockSize=256): #38 1032576 (
        hs_0: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_1: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_2: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_3: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_4: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_5: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        heads: ModuleList: #18 442368 (
          0: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          1: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          2: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          3: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          4: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          5: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
        )
        proj: Linear(inFeatures=384, outFeatures=384, bias=true): #2 <147456,384> 
        drop: Dropout(p=0.2, inplace=false): #0 <> 
      )
      ffwd: FeedForward(nEmbed = 384): #4 1181568 (
        net: Sequential: #4 1181568 (
          0: Linear(inFeatures=384, outFeatures=1536, bias=true): #2 <589824,1536> 
          1: ReLU: #0 <> 
          2: Linear(inFeatures=1536, outFeatures=384, bias=true): #2 <589824,384> 
          3: Dropout(p=0.2, inplace=false): #0 <> 
        )
      )
      ln1: TensorModule: #2 <384,384> 
      ln2: TensorModule: #2 <384,384> 
    )
    4: Block(nEmbed = 384): #46 2215680 (
      sa: MultiHeadAttention(numHeads=6, nEmbed=384, headSize=64, blockSize=256): #38 1032576 (
        hs_0: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_1: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_2: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_3: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_4: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_5: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        heads: ModuleList: #18 442368 (
          0: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          1: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          2: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          3: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          4: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          5: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
        )
        proj: Linear(inFeatures=384, outFeatures=384, bias=true): #2 <147456,384> 
        drop: Dropout(p=0.2, inplace=false): #0 <> 
      )
      ffwd: FeedForward(nEmbed = 384): #4 1181568 (
        net: Sequential: #4 1181568 (
          0: Linear(inFeatures=384, outFeatures=1536, bias=true): #2 <589824,1536> 
          1: ReLU: #0 <> 
          2: Linear(inFeatures=1536, outFeatures=384, bias=true): #2 <589824,384> 
          3: Dropout(p=0.2, inplace=false): #0 <> 
        )
      )
      ln1: TensorModule: #2 <384,384> 
      ln2: TensorModule: #2 <384,384> 
    )
    5: Block(nEmbed = 384): #46 2215680 (
      sa: MultiHeadAttention(numHeads=6, nEmbed=384, headSize=64, blockSize=256): #38 1032576 (
        hs_0: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_1: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_2: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_3: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_4: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        hs_5: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
          key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
          drop: Dropout(p=0.2, inplace=false): #0 <> 
        )
        heads: ModuleList: #18 442368 (
          0: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          1: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          2: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          3: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          4: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
          5: Head_2(n_embed=384, head_size=64, block_size=256): #3 73728 (
            key: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            query: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            value: Linear(inFeatures=384, outFeatures=64, bias=false): #1 <24576> 
            drop: Dropout(p=0.2, inplace=false): #0 <> 
          )
        )
        proj: Linear(inFeatures=384, outFeatures=384, bias=true): #2 <147456,384> 
        drop: Dropout(p=0.2, inplace=false): #0 <> 
      )
      ffwd: FeedForward(nEmbed = 384): #4 1181568 (
        net: Sequential: #4 1181568 (
          0: Linear(inFeatures=384, outFeatures=1536, bias=true): #2 <589824,1536> 
          1: ReLU: #0 <> 
          2: Linear(inFeatures=1536, outFeatures=384, bias=true): #2 <589824,384> 
          3: Dropout(p=0.2, inplace=false): #0 <> 
        )
      )
      ln1: TensorModule: #2 <384,384> 
      ln2: TensorModule: #2 <384,384> 
    )
  )
  ln_f: TensorModule: #2 <384,384> 
  lm_head: Linear(inFeatures=384, outFeatures=65, bias=true): #2 <24960,65> 
)
true
active.all.allocated : 2.0 B
active.all.current : 2.0 B
active.all.freed : 0.0 B
active.all.peak : 2.0 B
active.large_pool.allocated : 0.0 B
active.large_pool.current : 0.0 B
active.large_pool.freed : 0.0 B
active.large_pool.peak : 0.0 B
active.small_pool.allocated : 2.0 B
active.small_pool.current : 2.0 B
active.small_pool.freed : 0.0 B
active.small_pool.peak : 2.0 B
active_bytes.all.allocated : 256.0 KiB
active_bytes.all.current : 256.0 KiB
active_bytes.all.freed : 0.0 B
active_bytes.all.peak : 256.0 KiB
active_bytes.large_pool.allocated : 0.0 B
active_bytes.large_pool.current : 0.0 B
active_bytes.large_pool.freed : 0.0 B
active_bytes.large_pool.peak : 0.0 B
active_bytes.small_pool.allocated : 256.0 KiB
active_bytes.small_pool.current : 256.0 KiB
active_bytes.small_pool.freed : 0.0 B
active_bytes.small_pool.peak : 256.0 KiB
allocated_bytes.all.allocated : 256.0 KiB
allocated_bytes.all.current : 256.0 KiB
allocated_bytes.all.freed : 0.0 B
allocated_bytes.all.peak : 256.0 KiB
allocated_bytes.large_pool.allocated : 0.0 B
allocated_bytes.large_pool.current : 0.0 B
allocated_bytes.large_pool.freed : 0.0 B
allocated_bytes.large_pool.peak : 0.0 B
allocated_bytes.small_pool.allocated : 256.0 KiB
allocated_bytes.small_pool.current : 256.0 KiB
allocated_bytes.small_pool.freed : 0.0 B
allocated_bytes.small_pool.peak : 256.0 KiB
allocation.all.allocated : 2.0 B
allocation.all.current : 2.0 B
allocation.all.freed : 0.0 B
allocation.all.peak : 2.0 B
allocation.large_pool.allocated : 0.0 B
allocation.large_pool.current : 0.0 B
allocation.large_pool.freed : 0.0 B
allocation.large_pool.peak : 0.0 B
allocation.small_pool.allocated : 2.0 B
allocation.small_pool.current : 2.0 B
allocation.small_pool.freed : 0.0 B
allocation.small_pool.peak : 2.0 B
inactive_split.all.allocated : 1.0 B
inactive_split.all.current : 1.0 B
inactive_split.all.freed : 0.0 B
inactive_split.all.peak : 1.0 B
inactive_split.large_pool.allocated : 0.0 B
inactive_split.large_pool.current : 0.0 B
inactive_split.large_pool.freed : 0.0 B
inactive_split.large_pool.peak : 0.0 B
inactive_split.small_pool.allocated : 1.0 B
inactive_split.small_pool.current : 1.0 B
inactive_split.small_pool.freed : 0.0 B
inactive_split.small_pool.peak : 1.0 B
inactive_split_bytes.all.allocated : 1.9 MiB
inactive_split_bytes.all.current : 1.8 MiB
inactive_split_bytes.all.freed : 128.0 KiB
inactive_split_bytes.all.peak : 1.9 MiB
inactive_split_bytes.large_pool.allocated : 0.0 B
inactive_split_bytes.large_pool.current : 0.0 B
inactive_split_bytes.large_pool.freed : 0.0 B
inactive_split_bytes.large_pool.peak : 0.0 B
inactive_split_bytes.small_pool.allocated : 1.9 MiB
inactive_split_bytes.small_pool.current : 1.8 MiB
inactive_split_bytes.small_pool.freed : 128.0 KiB
inactive_split_bytes.small_pool.peak : 1.9 MiB
max_split_size : -1.0 B
num_alloc_retries : 0.0 B
num_ooms : 0.0 B
oversize_allocations.allocated : 0.0 B
oversize_allocations.current : 0.0 B
oversize_allocations.freed : 0.0 B
oversize_allocations.peak : 0.0 B
oversize_segments.allocated : 0.0 B
oversize_segments.current : 0.0 B
oversize_segments.freed : 0.0 B
oversize_segments.peak : 0.0 B
requested_bytes.all.allocated : 256.0 KiB
requested_bytes.all.current : 256.0 KiB
requested_bytes.all.freed : 0.0 B
requested_bytes.all.peak : 256.0 KiB
requested_bytes.large_pool.allocated : 0.0 B
requested_bytes.large_pool.current : 0.0 B
requested_bytes.large_pool.freed : 0.0 B
requested_bytes.large_pool.peak : 0.0 B
requested_bytes.small_pool.allocated : 256.0 KiB
requested_bytes.small_pool.current : 256.0 KiB
requested_bytes.small_pool.freed : 0.0 B
requested_bytes.small_pool.peak : 256.0 KiB
reserved_bytes.all.allocated : 2.0 MiB
reserved_bytes.all.current : 2.0 MiB
reserved_bytes.all.freed : 0.0 B
reserved_bytes.all.peak : 2.0 MiB
reserved_bytes.large_pool.allocated : 0.0 B
reserved_bytes.large_pool.current : 0.0 B
reserved_bytes.large_pool.freed : 0.0 B
reserved_bytes.large_pool.peak : 0.0 B
reserved_bytes.small_pool.allocated : 2.0 MiB
reserved_bytes.small_pool.current : 2.0 MiB
reserved_bytes.small_pool.freed : 0.0 B
reserved_bytes.small_pool.peak : 2.0 MiB
segment.all.allocated : 1.0 B
segment.all.current : 1.0 B
segment.all.freed : 0.0 B
segment.all.peak : 1.0 B
segment.large_pool.allocated : 0.0 B
segment.large_pool.current : 0.0 B
segment.large_pool.freed : 0.0 B
segment.large_pool.peak : 0.0 B
segment.small_pool.allocated : 1.0 B
segment.small_pool.current : 1.0 B
segment.small_pool.freed : 0.0 B
segment.small_pool.peak : 1.0 B
Device = Device(CUDA,-1)
13443137 parameters
learningRate = 1.0E-4
maxIterations = 41500
dropout = 0.2
GPU total = 24.0 GiB
GPU used = 6.9 GiB
13443137 parameters >= 53772548 bytes = 51.3 MiB
step 0: train loss 4.323465, val loss 4.313903, mem 633.8 MiB @ 00 00:00:00.000, mean 00 00:00:00.000
step 500: train loss 2.6450615, val loss 2.6477497, mem 737.0 MiB @ 00 00:01:01.511, mean 00 00:00:00.123
step 1000: train loss 2.6040258, val loss 2.592008, mem 737.0 MiB @ 00 00:02:02.949, mean 00 00:00:00.122
step 1500: train loss 2.6052911, val loss 2.5823283, mem 737.1 MiB @ 00 00:03:04.338, mean 00 00:00:00.122
step 2000: train loss 2.592185, val loss 2.573713, mem 737.2 MiB @ 00 00:04:05.673, mean 00 00:00:00.122
step 2500: train loss 2.5700061, val loss 2.5632617, mem 737.2 MiB @ 00 00:05:06.972, mean 00 00:00:00.122
step 3000: train loss 2.5861602, val loss 2.5553243, mem 739.5 MiB @ 00 00:06:08.208, mean 00 00:00:00.122
step 3500: train loss 2.558061, val loss 2.5490308, mem 739.5 MiB @ 00 00:07:09.408, mean 00 00:00:00.122
step 4000: train loss 2.548742, val loss 2.5421014, mem 739.5 MiB @ 00 00:08:10.607, mean 00 00:00:00.122
step 4500: train loss 2.5365088, val loss 2.5334082, mem 739.7 MiB @ 00 00:09:11.808, mean 00 00:00:00.122
step 5000: train loss 2.5347583, val loss 2.5292315, mem 740.0 MiB @ 00 00:10:12.999, mean 00 00:00:00.122
step 5500: train loss 2.530294, val loss 2.5230098, mem 740.0 MiB @ 00 00:11:14.195, mean 00 00:00:00.122
step 6000: train loss 2.5148194, val loss 2.515789, mem 740.0 MiB @ 00 00:12:15.358, mean 00 00:00:00.122
step 6500: train loss 2.5099423, val loss 2.5095465, mem 740.0 MiB @ 00 00:13:16.543, mean 00 00:00:00.122
step 7000: train loss 2.5146213, val loss 2.5127692, mem 740.5 MiB @ 00 00:14:17.721, mean 00 00:00:00.122
step 7500: train loss 2.5060015, val loss 2.504297, mem 740.5 MiB @ 00 00:15:18.875, mean 00 00:00:00.122
step 8000: train loss 2.5189407, val loss 2.5052562, mem 740.5 MiB @ 00 00:16:20.022, mean 00 00:00:00.122
step 8500: train loss 2.5036879, val loss 2.5054653, mem 740.5 MiB @ 00 00:17:21.178, mean 00 00:00:00.122
step 9000: train loss 2.496351, val loss 2.4987144, mem 740.5 MiB @ 00 00:18:22.318, mean 00 00:00:00.122
step 9500: train loss 2.4912844, val loss 2.4940393, mem 740.5 MiB @ 00 00:19:23.455, mean 00 00:00:00.122
step 10000: train loss 2.4919074, val loss 2.4977922, mem 740.5 MiB @ 00 00:20:24.601, mean 00 00:00:00.122
step 10500: train loss 2.4894023, val loss 2.4935718, mem 740.5 MiB @ 00 00:21:25.750, mean 00 00:00:00.122
step 11000: train loss 2.5133002, val loss 2.5183408, mem 740.6 MiB @ 00 00:22:26.872, mean 00 00:00:00.122
step 11500: train loss 2.5187078, val loss 2.5185654, mem 740.6 MiB @ 00 00:23:27.980, mean 00 00:00:00.122
step 12000: train loss 2.5184162, val loss 2.5199928, mem 740.6 MiB @ 00 00:24:29.138, mean 00 00:00:00.122
step 12500: train loss 2.5150337, val loss 2.51247, mem 740.6 MiB @ 00 00:25:30.262, mean 00 00:00:00.122
step 13000: train loss 2.5127447, val loss 2.510491, mem 740.6 MiB @ 00 00:26:31.351, mean 00 00:00:00.122
step 13500: train loss 2.5024757, val loss 2.5108242, mem 740.6 MiB @ 00 00:27:32.444, mean 00 00:00:00.122
step 14000: train loss 2.498589, val loss 2.4986157, mem 740.6 MiB @ 00 00:28:33.574, mean 00 00:00:00.122
step 14500: train loss 2.4960895, val loss 2.498068, mem 740.6 MiB @ 00 00:29:34.700, mean 00 00:00:00.122
